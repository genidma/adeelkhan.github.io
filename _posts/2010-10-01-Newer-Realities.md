# Newer realities

Okay, in one of my previous blogposts, I said that, [quote](https://stellardreams.github.io/Ethics-involving-Terraforming/) I am not a pro A.I fellow or an anti A.I fellow. 


* First of all, I do not think that we ought to categorize an intelligence as artificial. I think it makes more sense to categorize the intelligence as being substrate independent. There is a moral and ethical angle and as it relates to the classification of intelligence as intelligence or non. However the issue isn't necessarily as clear cut. And between Stephen Hawking, Daniel Dennett, Ray Kurzweil and others, there are different schools of thought on how this substrate independent intelligence should actually be powered. 
* Next, What I meant by that is that the ethical and actual implications of getting breakthroughs and as it relates to us taking steps towards artificial general intelligence is something that we should be mindful of. 
* I am worried that the structure of power dynamics and the way that it has historically evolved for our species, has been adversarial. 
* If we revive our economies using older models, then we will get the same outcomes. This is something that I expand upon in this blogpost. 
* However, there doesn't appear to be a clear path towards enabling co-operation. On the contrary, things seem to be moving in the opposite direction. 
* Enabling newer set of realities will require a fair bit of creative destruction. Being very mindful of the reality that how we have done things in the past, isn't how we are going to be doing things in the future. So we'd need a) Social safety nets. b) Sustainable means to be able to power these social safety nets on a timeline (50 to 100 years at the very least) c) Adequate succession planning and scenario planning. Just handing and training the next generation is not going to be enough. 
* Co-operation on a global basis is going to be key. Because the very technologies that we'd need to deploy in order to safeguard our collective future and the future of all the other species that share this planet with us. These very technoogies could indeed be weaponized and turned on us. One of the many many examples, we may have the theoretical capability of sending 100 kg payloads to Mars in as little as 3 days. But the same tech could also be abused in order to weaponize space. A potential scenario, that will be to our detriment then and in the future. When we may actually need such weaponry to blast off bigger set of rocks that we may not be able to disintegrate with the existing state of technology that we have. 
* I think the issues are going to get compounded. Because we may deal with further effects of climate change. I am not a climate scientist. So not sure how unpredictable the climate is going to get and when. 
* Also, I think automation is going to displace more jobs vs our ability to be able to create new, quality, well-paying jobs. And even if by some miracle, we manage to create hundreds of millions of quality jobs, then there is going to be a net regressive impact on the ecology. 
* If we go to other worlds in our own solar system and we find evidence of life there, then it's a huge ethical dilemna. Say, push comes to shove and we say, screw it. It's just bacteria and some shrubs and some somewhat intelligent octopuses. Even in such a scenario, we can do some back of the envelope calculations in order to determine when we are going to max out the capacity within our own solar system. I guess, by that time either be or would be on the path to enable structures, that would help us become a [type ii civilization on the Kardashev scale](https://en.wikipedia.org/wiki/Kardashev_scale). However, if we do end up wiping up bacteria and other life-forms on our path, then it's the same ethical dilemna. 
