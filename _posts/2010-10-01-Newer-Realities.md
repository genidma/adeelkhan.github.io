# Newer realities

Okay, in one of my previous blogposts, I said that, [quote](https://stellardreams.github.io/Ethics-involving-Terraforming/) I am not a pro A.I fellow or an anti A.I fellow. 

* First of all, classification of intelligence as artificial doesn't seem apt. The way I see it, our intelligence has been enabled because eukaryotic cells figured out how to co-operate over a very very longer stretch of time. Out of this co-operation, came pretty much all of the life that we see around us. Much of which has yet to be discovered and catalogued. Plus, all of the life we see around ourselves is only a tiny fraction of the life that has existed on this planet.  Plus, if we think about it, the species that are really thriving on this planet are actually bacteria and viruses. Left to their own, they'd be exposed to radiation from the sun and heat from all these different sources. These conditions would result into significantly shortening their lifespan and making for rather unpleasant living conditions. So maybe the cells are a lot more clever. First of all, biology has kept chains going for a very very long time. Secondly by creating complex structure that the cells can reside in, they've significantly increased their own lifespan - as well the quality of their life. This is not an original thought entirely. I have heard Dr. Martine Rothblatt say something along these lines and also Naveen Jain. 
* And so, I think it makes more sense to categorize intelligence that we are going to model-engineer, as being substrate independent. There is also a moral and ethical angle and as it relates to the classification of intelligence. Because if we classify something as artificial and that results into the automatic classification of that intelligence as non-conscious and it turns out that the intelligence is actually conscious. Then we have enabled suffering by design. However the issue isn't necessarily as clear cut. And between Stephen Hawking, Daniel Dennett, Ray Kurzweil and others, there are different schools of thought on how this substrate independent intelligence should actually be powered. Or if it should be powered at all. 
* Humans go crazy. What is the guarantee that an intelligence that is substrate independent is not going to go crazy. Whether because of a breakthrough and as it relates to it's architecture. Or because someone deliberately wanted it to go crazy. For whatever given purpose. 

Next and going back to that bit from my previous blogposst, what I meant by that is that the ethical and actual implications of getting breakthroughs and as it relates to us taking steps towards artificial general intelligence (substrate independent intelligence really) is something that we should be mindful of. 
* I am worried that the structure of power dynamics and the way that it has historically evolved for our species, has been adversarial. 
* There doesn't appear to be a clear path towards enabling co-operation. On the contrary, things seem to be moving in the opposite direction. We are seeing some wonderful and remarkable co-operation on the international space station. [Proof](https://blogs.nasa.gov/spacestation/2020/05/). On the surface, there are a lot more of us and we are breaking into each others systems, stealing intellectual property. Our leaders are threatening other leaders with trade wars. They are saying mean and hurtful things about each other. It's just a lot of problems. 
* I think that it's ridiculous to expect the government to solve all the problems. Specifically in a situation whereby a crisis is escalating. There is a threshold of how much stress a system can handle. If we exceed that threshold, then contingen upon the level of severity - we do not know what the outcome is going to be. 
* It's also important to note that different individuals have a different value system.
* If we revive our economies using older models, then we will get the same outcomes. This is something that I expand upon in the [following blogpost](https://stellardreams.github.io/Dealing-with-Outbreaks/). I think this is in the domain of deductive reasoning. But it seems logical and rational to assume that the same set of inputs patterns repeated, are going to yield a similar - if no a far worse outcome. It's highly unlikely that things are going to get better with the same set of inputs. Unless, there are interventions that are incentivized to specifically tackle the problems that arise. And then there are the unintended consequences. 
* On the other hand, enabling newer set of realities will require a fair bit of creative destruction. Being very mindful of the reality that how we have done things in the past, isn't how we are going to be doing things in the future. So we'd need a) Social safety nets. b) Sustainable means to be able to power these social safety nets on a timeline (50 to 100 years at the very least) c) Adequate succession planning and scenario planning. Just handling the algorithms over and training the next generation about the general understanding of the constructs is not going to be enough.
* Now the previous assumption about death/dying may turn out to be not true. Because we may tacklge ageing and disease. In such a scenario, how can we guarantee that newer ideas are going to surface. Also, beyond a certain actual age, should the person continue to reside in a finite geographic space and what are going to be the ethical and legal set of clauses that are going to govern such rulings. 
* Co-operation on a global basis is going to be key. Because the very technologies that we'd need to deploy in order to safeguard our collective future and the future of all the other species that share this planet with us. These very technoogies could indeed be weaponized and turned on us. One of the many many examples, we may have or possibly have (I haven't seen it with my own eyes) the theoretical capability of sending 100 kg payloads to Mars in as little as 3 days. But the same tech could also be abused in order to weaponize space. A potential scenario, that will be to our detriment then and in the future. When we may actually need such weaponry to blast off bigger set of rocks that we may not be able to disintegrate with the existing state of technology that we have. 
* I think the issues are going to get compounded. Because we may deal with further effects of climate change. I am not a climate scientist. So not sure how unpredictable the climate is going to get and when. 
* Also, I think automation is going to displace more jobs vs our ability to be able to create new, quality, well-paying jobs. And even if by some miracle, we manage to create hundreds of millions of quality jobs, then there is going to be a net regressive impact on the ecology. 
* If we go to other worlds in our own solar system and we find evidence of life there, then it's a huge ethical dilemna. Say, push comes to shove and we say, screw it. It's just bacteria and some shrubs and some somewhat intelligent octopuses. Even in such a scenario, we can do some back of the envelope calculations in order to determine when we are going to max out the capacity within our own solar system. I guess, by that time either be or would be on the path to enable structures, that would help us become a [type ii civilization on the Kardashev scale](https://en.wikipedia.org/wiki/Kardashev_scale). However, if we do end up wiping up bacteria and other life-forms on our path, then it's the same ethical dilemna. 

All of these are very linear definitions. 

One of the key correlates for getting to breakthroughs is someone who has been wrangling with a given set of conditions in their mind. And so, these problems and more are going to redefined by others. And in the process of doing so, we are going to come up with potential solutions to some of these very problems. 

I think it's a healthy thing to do. To thing about the different set of outcomes and how they could come about. What are the inputs that lead to certain conditions. What are the triggers and where do the necessary support structures exist. 

I'd appreciate it if you could give me feedback on how these blog-posts can be improved. As well, feedback on the how I should structure the processes that lead to constructing these thoughts in the first place. I think I need to take a more structure approach towards describing in chuks, what the proposition actually is. Then go about classifying and describing each one of the sections and then tie is all together.
