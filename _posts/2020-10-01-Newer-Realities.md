# Newer realities

Okay, in one of my previous blogposts, I said that, [quote](https://stellardreams.github.io/Ethics-involving-Terraforming/) I am not a pro A.I fellow or an anti A.I fellow. 

* If I may begin by sharing my thoughs on the actual usage of the words 'Artificial Intelligence'. The way I look at it, classification of intelligence as artificial doesn't seem apt. Intelligence appears to be an emergent phenomenon. Different systems and organisms exhibit their intelligence at difference scales.
* It took a really [long time on earth](https://en.wikipedia.org/wiki/Timeline_of_the_evolutionary_history_of_life) to go from from amino acids to primates.
* The theory goes that a single celled organism once ingested another single celled organism. The cell that was ingested could not be broken down and so it started living inside the other cell. Over time, the structures of cells became more complex. Cells developed more complex machinery in order to process energy. A lot more time were to pass, till we saw the emergence of multi-cellular organisms.  Out of this co-operation, came pretty much all of the life that we see around us. Much of which has yet to be discovered and catalogued. Plus, all of the life we see around ourselves is only a tiny fraction of the life that has existed on this planet. Possibly less than 1%. 
* As a side note, I think that we can expend a lot more resources, perhaps even enable entire new sub-branches of physics (all subjects roll up to physics, including biology) in order to learn and understand how cells actually function and how they communicate with each other. 
* Next, in terms of actual numbers and not in terms of [biomass](https://www.dictionary.com/browse/biomass): The species that are really thriving on this planet are actually [archaea](https://en.wikipedia.org/wiki/Archaea),[bacteria](https://en.wikipedia.org/wiki/Bacteria), [viruses](https://en.wikipedia.org/wiki/Virus). Regarding viruses and depending on the source, viruses are either categorized as either non-living (not life) or between life and non-life. But we can find all three of these pretty much everywhere on our planet. On the surface, in the soil, inside of other mulit-cellular organisms, in the oceans, in extreme environment (particularly archaea and I just found out about this). Bacteria and some archaea also help with various important functions in our bodies. Different types of infectious types could causes disease. 
* From an evolutionary perspective, left to their own the simpler single-celled lifeforms would be exposed to radiation from the sun and heat from all these different sources. These conditions would result into significantly shortening their lifespan and making for rather unpleasant living conditions. So maybe the life that is actually all around us is lot more clever than we can imagine. 
* Here,  and first of all, biology has kept chains going for a very very long time. I do not know much about chemistry and I am not aware of an actual structure that we can manufacture and how it will not experience any degradation over a longer stretch of time. Say hundreds of millions or billions of years. But biology, keeps out spinning copies of itself and there are all these variations and adaptations. Some examples that come to mind: It's actually quite remarkable, how efficient biology is in extracting materials from the environment and putting them to use. There are literally an infinite number of use-cases here. How plants intake nutrients from the soil and use them to infuse flowers with colours and smell. Or the process of xylem or phloem at that, which is a central process that it responsible for the nutritional intake for all plants and trees. Same with the infinite number of complex interactions that occur inside of our bodies and our brains.
* Next by creating complex structure that the cells can reside in, they've significantly increased their own lifespan - as well the quality of their life. This is not an original thought entirely. I have heard Dr. Martine Rothblatt say something along these lines and also Naveen Jain. The question is what sort of functions the cells actually perform and how they communicate with each other. I am curious what the underpinning for something would have been from an evolutionary perspective. Is it really just random variations or did cells, over a very very longer stretch of time decide that they need structures in which they will reside. I think this is the topic of [microbial intelligence](https://en.wikipedia.org/wiki/Microbial_intelligence). It's a topic that I do not know much about. 

<img src="/assets/images/Evolution-timeline.png">

> It seems rather ignorant to categorize all other lifeforms as non-intelligent. 

It seems like there is a lot that we do not know about our environment, with regards to the lifeforms that evolution has powered. And lifeforms that we intimately share this planet with. The process of conducting experiments in order to validate or refute a hypothesis is probably the best mechanism in order to make sense out of what we are observing. That being said, perhaps the mechanism via which we go about describing what ought to be considered as intelligent, is a model that needs revision. Maybe it shouldn't be about [instructions per second](https://en.wikipedia.org/wiki/FLOPS#:~:text=In%20computing%2C%20floating%20point%20operations,than%20measuring%20instructions%20per%20second).

Think about it this way, if the next [chicxulub](https://en.wikipedia.org/wiki/Chicxulub_impactor) does end up wiping out all humans and the majority of primates. The lifeform that will invariably survive are going to be bacteria, arachae and viruses. 

Shifting gears, I think it makes more sense to categorize intelligence that we are going to model or engineer, as being substrate independent. There is also a moral and ethical angle and as it relates to the classification of intelligence. Because if we classify something as artificial and that results into the automatic classification of that intelligence as non-conscious and it turns out that the intelligence is actually conscious. Then we have enabled suffering by design. However the issue isn't necessarily as clear cut. And between Stephen Hawking, Daniel Dennett, Ray Kurzweil and others, there are different schools of thought on how this substrate independent intelligence should actually be powered. Or if it should be powered at all. 
* Humans go crazy. What is the guarantee that an intelligence that is substrate independent is not going to go crazy. Whether because of a breakdown and as it relates to it's architecture. Or because someone deliberately wanted it to go crazy. For whatever given purpose.
* Next, there is data that biology has powered and humans are also creating tons and tons of data of different kinds. Some of which could actually be useful. It's not possible to mobilize an army of humans and get them to make sense out of this data. An architecture that is engineered seems like the ideal candidate for this purpose. I do not know a lot about machine learning. But basically you construct your data, you build these models and the way you construct your data is what determines the machine's ability to be able to make sense out of what you have architected. 
* So in a potential hypothethical situation in the very near future, we will need breakthoughs in specific domains and it turns out that the multi-decade long research that we have been doing across the symbolic school and now the connectionist school is actually quite useful. These models are already beginning to showcase how effective they are. I think and I could be wrong. But most of the growth has happened on the [connectionist school](https://en.wikipedia.org/wiki/Neural_network#Artificial_intelligence) side of things.  
* So, basically the fear is skynet. Let's think about this. This fear is expressed and usually there isn't a follow-up. The statement is something like this, machines are going to take over and kill everyone. However, the question one must ask of themselves are. If an intelligence can take any form, travel light distances and recapitulate on a non-terrestrial habitat. May not need as much power in order to boot its computational architecture and so may not require as much matter and energy in order to power the entire sum total of the reality that it or they are going to be inhabiting. Why would an intelligence like this would want to compete with humans, their creators for resources in a universe that is abundant with resources.
* Why is there a rather linear extrapolation of intelligence using exponential scales. Meaning, human level and AGI level and hen super AGI level. What if there are many different gradients of intelligence. And just before the super intelligence makes a clean exit off, they actually leave us with enough lower level gradients. Something that would comfortably power abundance for us for an indefinite amount of time. 
* Also, when I reason and I think I am trying to make sense out of this using first principles. The questions I ask myself are. a) First of all, why would an intelligence that we have engineered, want to serve a gazillion different requests from 10 billion different humans - unless it was specifically designed to do just that. b) How will this entity, how will this being evolve? c) Is it conscious and is it suffering if it is conscious. Is it suffering, period? Because, the way we categorize a being as conscious seems arbitrary. Has 4 legs, cannot do math - is non conscious  d) Will it go crazy serving hundreds of billions of request each week? e) What if it keeps evolving and we rely on a distributed cluster of these beings for our needs and then it goes caput. Then cluster dies. We revive it back, it functions for a bit and then dies again. Like an electric grid that caves in and the transformers blow out -  when there is too much load. No affliction to OpenAI. I think they are doing a pretty awesome job and from what very limited I gather about them. 


Next and going back to that bit from my previous blogpost, what I meant by that is that the ethical and actual implications of getting breakthroughs and as it relates to us taking steps towards artificial general intelligence (substrate independent intelligence really) is something that we should be mindful of. 
* I am worried that the structure of power dynamics and the way that it has historically evolved for our species, has been adversarial. Human stupidity worries me a lot more vs the threat of a super intelligence arising to wipe us all out. 
* There doesn't appear to be a clear path towards enabling co-operation. On the contrary, things seem to be moving in the opposite direction. We are seeing some wonderful and remarkable co-operation on the international space station. [Proof](https://blogs.nasa.gov/spacestation/2020/05/). On the surface, there are a lot more of us and we are breaking into each others systems, stealing intellectual property. Our leaders are threatening other leaders with trade wars. They are saying mean and hurtful things about each other. It's just a lot of problems. It's bad stuff. This is not how leaders behave. What will children think when they see leaders behaving like that. And how will the children behave when they grow up? When they grow up with nanotechnology and other advanced technologies around them. Hopefully the future generations are going to learn from the mistakes of the previous generations. So how some of us are behaving publicly are crucial lessons on things not to do.
* I also believe that it's ridiculous to expect the government to solve all the problems. Specifically in a situation whereby a crisis is escalating. There is a threshold of how much stress a system can handle. If we exceed that threshold, then contingent upon the level of severity - we do not know what the outcome is going to be. 
* It's also important to note that different individuals have a different value system.
* If we revive our economies using older models, then we will get the same outcomes. This is something that I expand upon in the [following blogpost](https://stellardreams.github.io/Dealing-with-Outbreaks/). I think this is in the domain of deductive reasoning. But it seems logical and rational to assume that the same set of input patterns repeated, are going to yield a similar - if no a far worse outcome. It's highly unlikely that things are going to get better with the same set of inputs. Unless, there are interventions that are incentivized to specifically tackle the problems that arise.  
* On the other hand, enabling newer set of realities will require a fair bit of creative destruction. Being very mindful of the reality that how we have done things in the past, isn't how we are going to be doing things in the future. So we'd need a) Social safety nets. b) Sustainable means to be able to power these social safety nets on a timeline (50 to 100 years at the very least) c) Adequate succession planning and scenario planning. Just handling the algorithms over and training the next generation about the general understanding of the constructs is not going to be enough. d) The economies across large portions of the western world are not centrally managed. And so far, the western world has lead the world and as it relates to new technological development. That may change in the future. But for now, it's also crucial to protect and nurture the smaller startups and players who will be going against the big incumbents. Specially incumbents who have overstayed for too long, have gamed the system *and* prevent new entrants from coming in, in order to provide better products and services. This is going to be true across many different verticals, possibly all verticals. This has already begun in some specific verticals, where the incumbents lobby governments in order to try and stall new and smaller players from competing. 
* Now the previous assumption about death/dying may turn out to be not true. Because we may tacklge ageing and disease. In such a scenario, how can we guarantee that newer ideas are going to surface. Also, beyond a certain actual age, should the person continue to reside in a finite geographic space and what are going to be the ethical and legal set of clauses that are going to govern such rulings. Timing is a big factor here. Because if the therapies are indeed made available and means of offsetting the load on the ecology is something that isn't taken into consideration. Then there is going to be a net regressive impact on the environment.
* Co-operation on a global basis is going to be key. Because the very technologies that we'd need to deploy in order to safeguard our collective future and the future of all the other species that share this planet with us. These very technoogies could indeed be weaponized and turned on us. One of the many many examples, we may have or possibly have (I haven't seen it with my own eyes) the theoretical capability of sending 100 kg payloads to Mars in as little as 3 days. But the same tech could also be abused in order to weaponize space. A potential scenario, that will be to our detriment then and also in the future. When we may actually need such weaponry to blast off bigger set of rocks that we may not be able to disintegrate with the existing state of technology that we have. 
* I think the issues are going to get compounded. Because we may deal with further effects of climate change. I am not a climate scientist. So not sure how unpredictable the climate is going to get and when. 
* Also, I think automation is going to displace more jobs vs our ability to be able to create new, quality, well-paying jobs. And even if by some miracle, we manage to create hundreds of millions of quality jobs, then there is going to be a net regressive impact on the ecology. 
* If we go to other worlds in our own solar system and we find evidence of life there, then it's a huge ethical dilemna. Say, push comes to shove and we say, screw it. It's just bacteria and some shrubs and some somewhat intelligent octopuses. Even in such a scenario, we can do some back of the envelope calculations in order to determine when we are going to max out the capacity within our own solar system. I guess, by that time either be or would be on the path to enable structures, that would help us become a [type ii civilization on the Kardashev scale](https://en.wikipedia.org/wiki/Kardashev_scale). However, if we do end up wiping up bacteria and other life-forms on our path, then it's the same ethical dilemna. 

Overall, it seems like safe and effective intelligence that has been engineered is going to be vital in order to build a different reality. 

It seems extremely counter-productive to power growth making use of what we have done in the past. It's also a very unsafe thing to do. We are powering a outbreak of a larger proportion on the timeline. And it could be much worse. It would be air-borne rabies or worse. We could shutdown all airlines for an indefinite amount of time and then some migratory bird that is infected is going to die and drop somewhere.

With the whole pandemic situation, I think there is a correlation with regards to all the anti-bacterial sprays and soaps that we use and forest fires. The bigger set of forest fires happen, because we put out the smaller set of fires. The bush, twigs, leaves and what not accumulate and then the whole thing lights up in a bigger blaze. Same with bacteria. We kill all the good ones with the bad ones. Probably over-prescribe too many anti-biotics. So when something like coronavirus does emerge, the impact is significant. To say the least. 

So not only are we deliberately creating conditions for the next big pandemic to emerge. At the same time, we are creating products that lower our immunity. This is an uneducate guess. But, I think this is what's going on.

There appear to be other problems in the forms of inputs that are contributing to the problem. 

It seems like I am jumping between subjects. But the coronavirus situation has negatively impacted the economy. Again, using the same inputs, same or similar outputs are going to be reached. 

I think it's important to reason using first principles and ask ourselves. If we do not completely over-haul the architecture of how we power civilization, then what set of outcomes will we be experiencing. If those outcomes are not good, then why aren't we looking at changing the architecture. Specifically from the perspective of innovations that are going to be driving the bulk of the economy for an extended time period. 

It also seem inconceivable that governments will continue to offer these pandemic specific social safety nets to their citizens. Without the means and ability to be able to power these social safety nets for an indefinite amount of time. If the governments did that, then they'd be in the red by a lot. I am thinking and I haven't done the math. On the the other hand, if a larger number of citizenry do not have the means or the ability to be able to feed their children, then there is going to be discontent.  

If discontent can somehow be avoided, then there is going to be starvation and misery. The last time that happened in history, a world war was to follow. However, now there are many nations that are armed with nuclear weapons. In the aftermath of even a small scale nuclear war, a [nuclear winter](https://en.wikipedia.org/wiki/Nuclear_winter) will follow. A reality that is bound to, quote, lead to widespread crop failure and famine (Source: Wikipedia)

I have to pause and think about what I am writing. Indeed it is absolutely possible that I am wrong about almost every single one of the things that I am documenting here. Indeed, some of the propositions are very significant. Yet, at the same time, what I am writing about isn't necessarily a brand new approach. In fact, the foundations for enabling these newer realities have been in motion for decades. 

When there was a discussion about transitioning to solar. I let it be known that we shoud think about the individuals and their families who are employed by companies in the coal industry. 

But now we are looking into multiple industries getting disrupted in a shorter time period.

The automated factories of the future that [Professor. Nills J. Nillsson](http://ai.stanford.edu/~nilsson/OnlinePubs-Nils/General%20Essays/AIMag05-02-002.pdf) had referred to, is something that has to happen. He shares a timeline of how long it could take to completely automate the entire supply chain system. Perhaps we are already on our way. Howver, it would not be prudent to leave this to chance. Even in the best case scenario, whereby radical abundance would have been powered for all the inhabitants in a completely safe and ecologically friendly way. Even in such a scenario, there could be people who are going to be angry and so it could very well be like [1811](https://en.wikipedia.org/wiki/Luddite) again. But instead of sending in the army and putting down the violence with the justified use of force. It would be much better if we thought about these problems in earnest and started preparing for them now. The ethical and humane thing to do, is to engage with a wider segment of the society and ask them how would they like to engage their minds and their bodies, in a reality where there isn't a necessity to attach work with the means and ability to be able to earn an income. Next, we would then need to work towards designing this reality whereby intelligent life is going to have many healthy avenues of exercising their bodies and keeping their minds engaged. This work, coupled with actually enabling the automated factories of the future will be tackled in a distributed manner. 

All of these are very linear definitions. 

One of the key correlates for getting to breakthroughs is someone who has been wrangling with a given set of conditions in their mind. I am certain that there are a lot of people on this planet. Individuals who have thought about some of the problems and opportunities highlighted in this blogpost. As well, associated areas. There are people who have solutions to these problems. There are individuals who can assist us in completely redefining some of these problems. 

I think it's a healthy thing to do. To thing about the different set of outcomes and how they could come about. What are the inputs that lead to certain conditions. What are the triggers and where do the necessary support structures exist. 

I'd appreciate it if you could give me feedback on how these blog-posts can be improved. As well, feedback on the how I should structure the processes that lead to constructing these thoughts in the first place. I think I need to take a more structure approach towards describing in chuks, what the proposition actually is. Then go about classifying and describing each one of the sections and then tie is all together.
